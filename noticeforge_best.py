# -*- coding: utf-8 -*-
"""
NoticeForge Core Logic v5.2 (Ultimate: DocuWorks/Excel-MD/LongPath/Binder)
"""
from __future__ import annotations
import os, sys, re, json, time, hashlib, csv, subprocess, html as _html
from dataclasses import dataclass, asdict
from typing import Dict, List, Tuple, Optional, Callable

# Tesseract ãƒã‚¤ãƒŠãƒªã®å€™è£œãƒ‘ã‚¹ï¼ˆè¤‡æ•°ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å ´æ‰€ã«å¯¾å¿œï¼‰
_TESSERACT_CANDIDATES = [
    r"C:\Program Files\Tesseract-OCR\tesseract.exe",
    r"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe",
    r"C:\Users\Public\Tesseract-OCR\tesseract.exe",
]

try:
    import fitz  # PyMuPDF
except Exception:
    fitz = None

TESSERACT_AVAILABLE = False
try:
    import pytesseract
    from PIL import Image
    # ãƒã‚¤ãƒŠãƒªã‚’è‡ªå‹•æ¤œå‡ºï¼ˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å ´æ‰€ãŒç•°ãªã‚‹ç’°å¢ƒã«å¯¾å¿œï¼‰
    _found_tesseract: Optional[str] = None
    for _tc in _TESSERACT_CANDIDATES:
        if os.path.isfile(_tc):
            _found_tesseract = _tc
            break
    if _found_tesseract is None:
        # PATHä¸Šã«ã‚ã‚‹å ´åˆï¼ˆLinux / Mac / PATHè¿½åŠ æ¸ˆã¿ã®Windowsï¼‰
        import shutil as _shutil
        if _shutil.which("tesseract"):
            _found_tesseract = "tesseract"
    if _found_tesseract:
        pytesseract.pytesseract.tesseract_cmd = _found_tesseract
        TESSERACT_AVAILABLE = True
except Exception:
    TESSERACT_AVAILABLE = False

try:
    from docx import Document
except Exception:
    Document = None

try:
    import openpyxl
    from openpyxl.styles import Font, Alignment, PatternFill
    from openpyxl.utils import get_column_letter
except Exception:
    openpyxl = None

try:
    import xlrd
except Exception:
    xlrd = None

try:
    import xdwlib
    XDWLIB_AVAILABLE = True
except Exception:
    XDWLIB_AVAILABLE = False

# Windowsã§ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œæ™‚ã«ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’è¡¨ç¤ºã—ãªã„è¨­å®š
_WIN_NO_CONSOLE: dict = (
    {"creationflags": 0x08000000} if sys.platform.startswith("win") else {}
)

def _build_xdw2text_candidates() -> List[str]:
    """xdw2text.exeã®å€™è£œãƒ‘ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
    ãƒ¬ã‚¸ã‚¹ãƒˆãƒªè‡ªå‹•æ¤œå‡º â†’ Program Fileså…¨ä½“ã‚¹ã‚­ãƒ£ãƒ³ â†’ å›ºå®šãƒ‘ã‚¹ã®é †ã§æ¢ã™ã€‚
    TokiwaWorks / DocuWorks Viewer / ä»»æ„ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è‡ªå‹•æ¤œå‡ºã§ãã‚‹ã€‚"""
    candidates: List[str] = ["xdw2text"]  # ã¾ãšPATHä¸Šã‚’æ¢ã™

    if sys.platform.startswith("win"):
        # â”€â”€ æ–¹æ³•â‘ : Windowsãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‚’æ¤œç´¢ã—ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ‘ã‚¹ã‚’è‡ªå‹•æ¤œå‡º â”€â”€
        try:
            import winreg
            reg_keys = [
                (winreg.HKEY_LOCAL_MACHINE, r"SOFTWARE\Fuji Xerox\DocuWorks"),
                (winreg.HKEY_LOCAL_MACHINE, r"SOFTWARE\WOW6432Node\Fuji Xerox\DocuWorks"),
                (winreg.HKEY_LOCAL_MACHINE, r"SOFTWARE\FUJIFILM\DocuWorks"),
                (winreg.HKEY_LOCAL_MACHINE, r"SOFTWARE\WOW6432Node\FUJIFILM\DocuWorks"),
                (winreg.HKEY_LOCAL_MACHINE, r"SOFTWARE\Fujitsu\DocuWorks"),
                (winreg.HKEY_LOCAL_MACHINE, r"SOFTWARE\WOW6432Node\Fujitsu\DocuWorks"),
                (winreg.HKEY_LOCAL_MACHINE, r"SOFTWARE\TokiwaWorks\TokiwaWorks"),
                (winreg.HKEY_LOCAL_MACHINE, r"SOFTWARE\WOW6432Node\TokiwaWorks\TokiwaWorks"),
                (winreg.HKEY_CURRENT_USER,  r"SOFTWARE\Fuji Xerox\DocuWorks"),
                (winreg.HKEY_CURRENT_USER,  r"SOFTWARE\FUJIFILM\DocuWorks"),
                (winreg.HKEY_CURRENT_USER,  r"SOFTWARE\TokiwaWorks\TokiwaWorks"),
            ]
            for hive, key_path in reg_keys:
                try:
                    key = winreg.OpenKey(hive, key_path)
                    for value_name in ("InstallPath", "Path", "Install_Dir", ""):
                        try:
                            install_path, _ = winreg.QueryValueEx(key, value_name)
                            exe = os.path.join(str(install_path), "xdw2text.exe")
                            if os.path.isfile(exe) and exe not in candidates:
                                candidates.insert(1, exe)
                        except Exception:
                            continue
                except Exception:
                    continue
        except Exception:
            pass

        # â”€â”€ æ–¹æ³•â‘¡: C:\Program Files ä»¥ä¸‹ã‚’ glob ã§è‡ªå‹•ã‚¹ã‚­ãƒ£ãƒ³ â”€â”€
        # TokiwaWorks / DocuWorks Viewer ãªã©ä»»æ„ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å…ˆã‚’æ¤œå‡ºã§ãã‚‹
        try:
            import glob as _glob
            for pattern in [
                r"C:\Program Files\*\xdw2text.exe",
                r"C:\Program Files (x86)\*\xdw2text.exe",
                r"C:\Program Files\*\*\xdw2text.exe",
                r"C:\Program Files (x86)\*\*\xdw2text.exe",
            ]:
                for found in _glob.glob(pattern):
                    if found not in candidates:
                        candidates.insert(1, found)
        except Exception:
            pass

        # â”€â”€ æ–¹æ³•â‘¢: å›ºå®šãƒ‘ã‚¹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ â”€â”€
        candidates += [
            r"C:\Program Files\Fuji Xerox\DocuWorks\xdw2text.exe",
            r"C:\Program Files (x86)\Fuji Xerox\DocuWorks\xdw2text.exe",
            r"C:\Program Files\FUJIFILM\DocuWorks\xdw2text.exe",
            r"C:\Program Files (x86)\FUJIFILM\DocuWorks\xdw2text.exe",
            r"C:\Program Files\TokiwaWorks\xdw2text.exe",
            r"C:\Program Files (x86)\TokiwaWorks\xdw2text.exe",
            r"C:\Program Files\DocuWorks\xdw2text.exe",
            r"C:\Program Files (x86)\DocuWorks\xdw2text.exe",
        ]
    return candidates

# èµ·å‹•æ™‚ã«å€™è£œãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰ï¼ˆãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‚‚å‚ç…§ï¼‰
XDW2TEXT_CANDIDATES = _build_xdw2text_candidates()
# ä¸€åº¦è¦‹ã¤ã‹ã£ãŸå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«7å›è©¦è¡Œã—ãªãã¦æ¸ˆã‚€ï¼‰
_XDW2TEXT_PATH: Optional[str] = None

def _build_xdoc2txt_candidates() -> List[str]:
    """xdoc2txt.exeã®å€™è£œãƒ‘ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
    xdoc2txtã¯DocuWorks(.xdw)ã‚’å«ã‚€å¤šå½¢å¼ã«å¯¾å¿œã—ãŸç„¡æ–™ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºãƒ„ãƒ¼ãƒ«ã€‚
    https://ebstudio.info/home/xdoc2txt.html"""
    candidates: List[str] = ["xdoc2txt"]  # ã¾ãšPATHä¸Šã‚’æ¢ã™
    if sys.platform.startswith("win"):
        try:
            import glob as _glob
            for pattern in [
                r"C:\Program Files\xdoc2txt\xdoc2txt.exe",
                r"C:\Program Files (x86)\xdoc2txt\xdoc2txt.exe",
                r"C:\Program Files\*\xdoc2txt.exe",
                r"C:\Program Files (x86)\*\xdoc2txt.exe",
                r"C:\tools\xdoc2txt\xdoc2txt.exe",
                r"C:\xdoc2txt\xdoc2txt.exe",
            ]:
                for found in _glob.glob(pattern):
                    if found not in candidates:
                        candidates.insert(1, found)
        except Exception:
            pass
        candidates += [
            r"C:\Program Files\xdoc2txt\xdoc2txt.exe",
            r"C:\Program Files (x86)\xdoc2txt\xdoc2txt.exe",
        ]
    return candidates

XDOC2TXT_CANDIDATES = _build_xdoc2txt_candidates()
_XDOC2TXT_PATH: Optional[str] = None

DEFAULTS: Dict[str, object] = {
    "min_chars_mainbody": 400, # åŸºæº–ã‚’å°‘ã—ç”˜ãã—ã¦æŠ½å‡ºæ¼ã‚Œã‚’é˜²æ­¢
    "max_depth": 30,
    "summary_chars": 900,
    "main_attach_split_keywords": [r"^\s*åˆ¥æ·»", r"^\s*åˆ¥ç´™", r"^\s*ã€åˆ¥æ·»ã€‘", r"^\s*ã€åˆ¥ç´™ã€‘", r"^\s*ã€å‚è€ƒã€‘", r"^\s*è¨˜\s*$"],
    "bind_bytes_limit": 15 * 1024 * 1024,
    "use_ocr": False,
}

FACILITY_TAGS: Dict[str, List[str]] = {
    "è£½é€ æ‰€": [r"è£½é€ æ‰€"],
    "å±‹å¤–ã‚¿ãƒ³ã‚¯è²¯è”µæ‰€": [r"å±‹å¤–ã‚¿ãƒ³ã‚¯è²¯è”µæ‰€", r"æµ®å±‹æ ¹", r"å›ºå®šå±‹æ ¹", r"ã‚¢ãƒ‹ãƒ¥ãƒ©", r"ã‚¿ãƒ³ã‚¯åº•", r"æ³¡æ”¾å°„", r"é˜²æ²¹å ¤"],
    "å±‹å†…è²¯è”µæ‰€": [r"å±‹å†…è²¯è”µæ‰€"],
    "åœ°ä¸‹ã‚¿ãƒ³ã‚¯è²¯è”µæ‰€": [r"åœ°ä¸‹ã‚¿ãƒ³ã‚¯è²¯è”µæ‰€", r"FRPã‚¿ãƒ³ã‚¯", r"æ¼ãˆã„æ¤œçŸ¥"],
    "ç°¡æ˜“ã‚¿ãƒ³ã‚¯è²¯è”µæ‰€": [r"ç°¡æ˜“ã‚¿ãƒ³ã‚¯è²¯è”µæ‰€"],
    "ç§»å‹•ã‚¿ãƒ³ã‚¯è²¯è”µæ‰€": [r"ç§»å‹•ã‚¿ãƒ³ã‚¯è²¯è”µæ‰€", r"ã‚¿ãƒ³ã‚¯ãƒ­ãƒ¼ãƒªãƒ¼"],
    "çµ¦æ²¹å–æ‰±æ‰€": [r"çµ¦æ²¹å–æ‰±æ‰€", r"è¨ˆé‡æ©Ÿ", r"ãƒã‚ºãƒ«", r"\bSS\b", r"ã‚µãƒ¼ãƒ“ã‚¹ã‚¹ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³"],
    "è²©å£²å–æ‰±æ‰€": [r"è²©å£²å–æ‰±æ‰€"],
    "ç§»é€å–æ‰±æ‰€": [r"ç§»é€å–æ‰±æ‰€", r"è·å¸ã—", r"è·ç©ã¿"],
    "ä¸€èˆ¬å–æ‰±æ‰€": [r"ä¸€èˆ¬å–æ‰±æ‰€", r"å¡—è£…", r"æ´—æµ„", r"æ··åˆ", r"å……å¡«", r"ä¹¾ç‡¥"],
    "å…±é€š": [r"å±é™ºç‰©", r"æ¶ˆé˜²æ³•", r"æ”¿ä»¤", r"è¦å‰‡", r"é‹ç”¨", r"å–æ‰±ã„", r"è³ªç–‘", r"Q&A", r"è§£é‡ˆ"],
}

WORK_TAGS: Dict[str, List[str]] = {
    "ç”³è«‹ãƒ»å±Šå‡º": [r"è¨±å¯", r"å±Šå‡º", r"ç”³è«‹", r"å¤‰æ›´", r"ä»®ä½¿ç”¨", r"å®Œæˆæ¤œæŸ»", r"äºˆé˜²è¦ç¨‹", r"æ‰¿èª", r"å±Šæ›¸", r"æ§˜å¼"],
    "æŠ€è¡“åŸºæº–ãƒ»è¨­å‚™": [r"æŠ€è¡“åŸºæº–", r"åŸºæº–", r"æ§‹é€ ", r"è¨­å‚™", r"é…ç®¡", r"ã‚¿ãƒ³ã‚¯", r"ä¿æœ‰ç©ºåœ°", r"è€éœ‡", r"è…é£Ÿ", r"æ¼ãˆã„æ¤œçŸ¥"],
    "é‹ç”¨è§£é‡ˆãƒ»Q&A": [r"å–æ‰±ã„", r"é‹ç”¨", r"è§£é‡ˆ", r"è³ªç–‘", r"å•", r"ç­”", r"Q&A", r"ç…§ä¼š", r"å›ç­”"],
    "äº‹æ•…ãƒ»æ¼ãˆã„ãƒ»ç«ç½": [r"äº‹æ•…", r"æ¼ãˆã„", r"æµå‡º", r"ç«ç½", r"çˆ†ç™º", r"ç½å®³", r"åŸå› ", r"å†ç™ºé˜²æ­¢"],
    "æ¶ˆç«ãƒ»é˜²ç½": [r"æ³¡", r"æ¶ˆç«", r"å›ºå®šæ¶ˆç«", r"è­¦å ±", r"ç·Šæ€¥é®æ–­", r"é¿é›£", r"é˜²ç½", r"æ¶ˆç«è¨­å‚™"],
    "ç«‹å…¥æ¤œæŸ»ãƒ»æŒ‡å°": [r"ç«‹å…¥", r"æ¤œæŸ»", r"æŒ‡å°", r"æ˜¯æ­£", r"æ”¹å–„", r"ç¢ºèª", r"ç‚¹æ¤œ", r"å ±å‘Š"],
    "æ•™è‚²ãƒ»ä½“åˆ¶": [r"ä¿å®‰ç›£ç£", r"å±é™ºç‰©ä¿å®‰ç›£ç£è€…", r"ä¿å®‰çµ±æ‹¬", r"æ•™è‚²", r"è¨“ç·´", r"ä½“åˆ¶", r"è²¬ä»»è€…"],
}

@dataclass
class Record:
    relpath: str
    ext: str
    size: int
    mtime: float
    sha1: str
    method: str
    pages: Optional[int]
    text_chars: int
    needs_review: bool
    reason: str
    title_guess: str
    date_guess: str
    issuer_guess: str
    summary: str
    tags_facility: List[str]
    tags_work: List[str]
    tag_evidence: Dict[str, List[str]]
    out_txt: str
    full_text_for_bind: str = ""

def get_safe_path(path: str) -> str:
    """Windowsã®260æ–‡å­—åˆ¶é™(MAX_PATH)ã‚’çªç ´ã™ã‚‹ãŸã‚ã®å®‰å…¨ãªãƒ‘ã‚¹å¤‰æ›"""
    abs_path = os.path.abspath(path)
    if sys.platform.startswith("win") and not abs_path.startswith("\\\\?\\"):
        return "\\\\?\\" + abs_path
    return abs_path

def extract_pdf(path: str, use_ocr: bool) -> Tuple[str, Optional[int], str]:
    if not fitz: return "", None, "pymupdf_missing"
    text_parts = []
    method = "pdf_text"
    try:
        doc = fitz.open(get_safe_path(path))
        pages = doc.page_count
        for i in range(pages):
            page = doc.load_page(i)
            page_text = page.get_text("text") or ""
            # OCRåˆ¤æ–­:
            #   use_ocr=True â†’ 50æ–‡å­—æœªæº€ã®ãƒšãƒ¼ã‚¸ã«OCRï¼ˆæ‰‹å‹•æŒ‡å®šãƒ¢ãƒ¼ãƒ‰ï¼‰
            #   use_ocr=False â†’ 10æ–‡å­—æœªæº€ã®æ¥µç«¯ã«ç©ºãªãƒšãƒ¼ã‚¸ã«ã®ã¿è‡ªå‹•OCRï¼ˆç”»åƒPDFè‡ªå‹•æ¤œå‡ºï¼‰
            ocr_trigger = 50 if use_ocr else 10
            if len(page_text.strip()) < ocr_trigger and TESSERACT_AVAILABLE:
                try:
                    pix = page.get_pixmap(dpi=200)
                    img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                    ocr_text = pytesseract.image_to_string(img, lang="jpn")
                    ocr_text = re.sub(r'([ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥])\s+([ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥])', r'\1\2', ocr_text)
                    if ocr_text.strip():
                        # å®Œå…¨ã«ç©ºã ã£ãŸãƒšãƒ¼ã‚¸ã¯OCRçµæœã§ç½®æ›ã€ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã£ãŸå ´åˆã¯è¿½è¨˜
                        page_text = ocr_text if len(page_text.strip()) < 10 else page_text + "\n" + ocr_text
                        method = "pdf_ocr" if use_ocr else "pdf_ocr_auto"
                except Exception:
                    pass
            text_parts.append(page_text)
        doc.close()
        return "\n".join(text_parts), pages, method
    except Exception as e:
        return "", None, f"pdf_err:{e.__class__.__name__}"

def extract_docx(path: str) -> Tuple[str, str]:
    if not Document: return "", "docx_missing"
    try:
        doc = Document(get_safe_path(path))
        parts = [p.text for p in doc.paragraphs if p.text.strip()]
        for table in doc.tables:
            for row in table.rows:
                cells = [cell.text.strip().replace("\n", " ") for cell in row.cells]
                if any(cells):
                    parts.append("| " + " | ".join(cells) + " |")
        return "\n".join(parts), "docx_text"
    except Exception as e:
        return "", f"docx_err:{e.__class__.__name__}"

def extract_excel(path: str) -> Tuple[str, str]:
    """æ–°æ—§ã‚¨ã‚¯ã‚»ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€AIãŒç†è§£ã—ã‚„ã™ã„Markdownè¡¨å½¢å¼ã«æ•´å½¢ã™ã‚‹"""
    out = []
    ext = os.path.splitext(path)[1].lower()
    safe_p = get_safe_path(path)
    try:
        if ext in (".xlsx", ".xlsm") and openpyxl:
            wb = openpyxl.load_workbook(safe_p, data_only=True, read_only=True)
            for ws in wb.worksheets[:10]:
                out.append(f"## Sheet: {ws.title}")
                for row in ws.iter_rows(max_row=400, max_col=40, values_only=True):
                    if any(row):
                        out.append("| " + " | ".join([str(c).strip().replace("\n", " ") if c is not None else "" for c in row]) + " |")
                out.append("")
            wb.close()
            return "\n".join(out), "xlsx_md"
        elif ext == ".xls" and xlrd:
            wb = xlrd.open_workbook(safe_p)
            for sheet_idx in range(min(10, wb.nsheets)):
                ws = wb.sheet_by_index(sheet_idx)
                out.append(f"## Sheet: {ws.name}")
                for row_idx in range(min(400, ws.nrows)):
                    row = ws.row_values(row_idx)
                    if any(row):
                        out.append("| " + " | ".join([str(c).strip().replace("\n", " ") if c else "" for c in row]) + " |")
                out.append("")
            return "\n".join(out), "xls_md"
        else:
            return "", "excel_lib_missing"
    except Exception as e:
        return "", f"excel_err:{e.__class__.__name__}"

def extract_xdw(path: str) -> Tuple[str, str]:
    """DocuWorksã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹ã€‚
    xdwlibï¼ˆPythonãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ï¼‰ã‚’å„ªå…ˆã—ã€æ¬¡ã«xdw2text.exeã‚’è©¦ã¿ã‚‹ã€‚
    ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã¯ä¸€åˆ‡è¡¨ç¤ºã—ãªã„ã€‚"""
    global _XDW2TEXT_PATH
    safe_p = get_safe_path(path)

    # æ–¹æ³•1: xdwlibï¼ˆPythonè£½DocuWorksãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ï¼‰ã‚’å„ªå…ˆçš„ã«è©¦ã™
    if XDWLIB_AVAILABLE:
        try:
            doc = xdwlib.xdwopen(path)
            texts = [doc[pg].text for pg in range(doc.pages)]
            doc.close()
            result = "\n".join(texts)
            if result.strip():
                return result, "xdw_xdwlib"
        except Exception:
            pass  # å¤±æ•—ã—ãŸã‚‰xdw2textã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

    # æ–¹æ³•2: xdw2text.exe ã‚’è©¦ã™
    # ä¸€åº¦è¦‹ã¤ã‹ã£ãŸãƒ‘ã‚¹ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿ãªã‚‰1å›ã ã‘è©¦ã™ï¼ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å¤šç™ºã‚’é˜²æ­¢ï¼‰
    # ã¾ã è¦‹ã¤ã‹ã£ã¦ã„ãªã„å ´åˆã¯å…¨å€™è£œã‚’é †ã«è©¦ã™
    candidates_to_try = [_XDW2TEXT_PATH] if _XDW2TEXT_PATH else XDW2TEXT_CANDIDATES

    for cmd in candidates_to_try:
        if not cmd:
            continue
        try:
            result = subprocess.run(
                [cmd, safe_p],
                capture_output=True,
                text=True,
                encoding="cp932",
                errors="ignore",
                timeout=30,
                **_WIN_NO_CONSOLE,   # â† Windowsã®ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’éè¡¨ç¤º
            )
            if result.returncode == 0:
                _XDW2TEXT_PATH = cmd  # ä½¿ãˆã‚‹exeã‚’è¨˜æ†¶ã—ã¦æ¬¡å›ä»¥é™ã®æ¢ç´¢ã‚’çœç•¥
                if result.stdout.strip():
                    return result.stdout, "xdw_text"
                return "", "xdw_empty_or_protected"  # ãƒ„ãƒ¼ãƒ«ã¯å‹•ã„ãŸãŒãƒ•ã‚¡ã‚¤ãƒ«ãŒç©º
        except FileNotFoundError:
            if cmd == _XDW2TEXT_PATH:
                _XDW2TEXT_PATH = None  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒç„¡åŠ¹ã«ãªã£ãŸã®ã§ãƒªã‚»ãƒƒãƒˆ
            continue
        except Exception:
            continue

    # æ–¹æ³•3: xdoc2txt.exe ã‚’è©¦ã™ï¼ˆç„¡æ–™ãƒ„ãƒ¼ãƒ«: https://ebstudio.info/home/xdoc2txt.htmlï¼‰
    # DocuWorks Viewer Light ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã¨ DocuWorks Content Filter (iFilter) ãŒ
    # è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã‚‹ãŸã‚ã€-i ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ XDW ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã§ãã‚‹ã€‚
    global _XDOC2TXT_PATH
    xdoc2txt_candidates = [_XDOC2TXT_PATH] if _XDOC2TXT_PATH else XDOC2TXT_CANDIDATES
    for cmd in xdoc2txt_candidates:
        if not cmd:
            continue
        # ã¾ãš -i (iFilter) ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§è©¦ã™ â†’ DocuWorks Viewer Light ã® iFilter ã‚’åˆ©ç”¨
        for args in [[cmd, "-i", safe_p], [cmd, safe_p]]:
            try:
                result = subprocess.run(
                    args,
                    capture_output=True,
                    text=True,
                    encoding="cp932",
                    errors="ignore",
                    timeout=30,
                    **_WIN_NO_CONSOLE,
                )
                if result.returncode == 0 and result.stdout.strip():
                    _XDOC2TXT_PATH = cmd
                    method_name = "xdw_xdoc2txt_ifilter" if "-i" in args else "xdw_xdoc2txt"
                    return result.stdout, method_name
            except FileNotFoundError:
                if cmd == _XDOC2TXT_PATH:
                    _XDOC2TXT_PATH = None
                break  # ã“ã®cmdã¯å­˜åœ¨ã—ãªã„ã®ã§æ¬¡ã®cmdã¸
            except Exception:
                break

    return "", "xdw2text_missing (è¦xdw2text.exe ã¾ãŸã¯ xdoc2txt.exe å°å…¥: DocuWorksãƒ•ã‚©ãƒ«ãƒ€å†… ã¾ãŸã¯ https://ebstudio.info/home/xdoc2txt.html)"

def split_main_attach(text: str, kws: List[str]) -> Tuple[str, str]:
    lines = text.splitlines()
    cut_idx = -1
    for i, line in enumerate(lines):
        for k in kws:
            if re.match(k, line):
                cut_idx = i
                break
        if cut_idx != -1: break

    if cut_idx > 5:
        main_text = "\n".join(lines[:cut_idx])
        attach_text = "\n".join(lines[cut_idx:])
        return main_text.strip(), attach_text.strip()
    return text.strip(), ""

def convert_japanese_year(text: str) -> str:
    def replacer(match):
        era = match.group(1)
        year_str = match.group(2)
        year = 1 if year_str == "å…ƒ" else int(year_str)
        if era == "ä»¤å’Œ": west_year = 2018 + year
        elif era == "å¹³æˆ": west_year = 1988 + year
        elif era == "æ˜­å’Œ": west_year = 1925 + year
        else: return match.group(0)
        return f"{match.group(0)}ï¼ˆ{west_year}å¹´ï¼‰"
    return re.sub(r"(ä»¤å’Œ|å¹³æˆ|æ˜­å’Œ)\s*([0-9å…ƒ]+)\s*å¹´", replacer, text)

# é€šçŸ¥ã‚¿ã‚¤ãƒˆãƒ«ã®å…¸å‹çš„ãªæœ«å°¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ—¥æœ¬ã®å…¬æ–‡æ›¸ï¼‰
_TITLE_ENDINGS = (
    r"ã«ã¤ã„ã¦[ï¼ˆ(]?é€šçŸ¥[ï¼‰)]?\s*$", r"ã«ã¤ã„ã¦\s*$", r"ã«é–¢ã™ã‚‹ä»¶\s*$",
    r"ã«é–¢ã—ã¦\s*$", r"ã«ä¿‚ã‚‹ä»¶\s*$", r"ã®ä»¶\s*$",
)
# ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®å…¸å‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ–‡æ›¸ç•ªå·ãƒ»æ—¥ä»˜ãƒ»å®›å…ˆãƒ»ç™ºå‡ºè€…ãªã©ï¼‰
_HEADER_PATTERNS = (
    r"^ç¬¬\d+å·", r"^[æ¶ˆç·å±]é˜²[äºˆæ–½ç«‹]?ç¬¬", r"^\d{4}å¹´", r"^ä»¤å’Œ|^å¹³æˆ|^æ˜­å’Œ",
    r"å„éƒ½é“åºœçœŒ|å„æ¶ˆé˜²æœ¬éƒ¨|å„å¸‚ç”ºæ‘", r"æ®¿\s*$", r"å¾¡ä¸­\s*$",
    r"^æ¶ˆé˜²åº|^ç·å‹™çœ|^å±é™ºç‰©ä¿å®‰å®¤|^äºˆé˜²èª²", r"å®˜å°çœç•¥",
)

def guess_title(text: str, fallback: str) -> str:
    """é€šçŸ¥ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ¨å®šã™ã‚‹ï¼ˆã€Œã€œã«ã¤ã„ã¦ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å„ªå…ˆã€ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰"""
    lines = text.splitlines()
    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: ã€Œã€œã«ã¤ã„ã¦ã€ã€Œã€œã«é–¢ã™ã‚‹ä»¶ã€ã§çµ‚ã‚ã‚‹è¡Œã‚’å„ªå…ˆï¼ˆé€šçŸ¥ã‚¿ã‚¤ãƒˆãƒ«ã®å…¸å‹å½¢ï¼‰
    for line in lines[:100]:
        s = line.strip()
        if 10 <= len(s) <= 150:
            if any(re.search(pat, s) for pat in _TITLE_ENDINGS):
                return s
    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æœ€åˆã®æ„å‘³ã®ã‚ã‚‹è¡Œã‚’å–ã‚‹
    for line in lines[:80]:
        s = line.strip()
        if len(s) < 8 or len(s) > 150:
            continue
        if re.match(r"^[\d\-\s\(\)ï¼ˆï¼‰ãƒ» ã€€]+$", s):
            continue
        if any(re.search(p, s) for p in _HEADER_PATTERNS):
            continue
        return s
    return fallback

def guess_date(text: str) -> str:
    m = re.search(r"(ä»¤å’Œ|å¹³æˆ|æ˜­å’Œ)\s*[0-9å…ƒ]+\s*å¹´\s*\d+\s*æœˆ\s*\d+\s*æ—¥(ï¼ˆ\d{4}å¹´ï¼‰)?", text)
    if m: return m.group(0)
    m2 = re.search(r"\d{4}\s*å¹´\s*\d{1,2}\s*æœˆ\s*\d{1,2}\s*æ—¥", text)
    return m2.group(0) if m2 else ""

def guess_issuer(text: str) -> str:
    for cand in ["æ¶ˆé˜²åº", "ç·å‹™çœæ¶ˆé˜²åº", "æ¶ˆé˜²å±€", "å±é™ºç‰©ä¿å®‰å®¤", "äºˆé˜²èª²"]:
        if cand in text: return cand
    return ""

def tag_text(text: str) -> Tuple[List[str], List[str], Dict[str, List[str]]]:
    ev: Dict[str, List[str]] = {}; fac: List[str] = []; work: List[str] = []
    target = text[:8000]
    for t, ps in FACILITY_TAGS.items():
        if hits := [p for p in ps if re.search(p, target)]:
            fac.append(t); ev[t] = hits[:3]
    for t, ps in WORK_TAGS.items():
        if hits := [p for p in ps if re.search(p, target)]:
            work.append(t); ev[t] = hits[:3]
    if not fac and re.search(r"å±é™ºç‰©|æ¶ˆé˜²æ³•", target): fac.append("å…±é€š")
    return fac, work, ev

def _format_summary(core: str, n: int) -> str:
    """æ¦‚è¦ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿ã‚„ã™ãæ•´å½¢ã™ã‚‹ï¼ˆç©ºè¡Œã‚’é–“å¼•ãã€çµ‚ç«¯è¡Œã§ã‚¹ãƒˆãƒƒãƒ—ï¼‰"""
    result_lines: List[str] = []
    char_count = 0
    prev_blank = False
    for line in core.splitlines():
        stripped = line.strip()
        # ã€Œä»¥ä¸Šã€ã€Œä»¥ä¸‹ä½™ç™½ã€ãªã©ã®çµ‚ç«¯è¡Œã§ã‚¹ãƒˆãƒƒãƒ—
        if re.match(r"^\s*(ä»¥ä¸Š|ä»¥ä¸‹ä½™ç™½|ï¼ˆäº†ï¼‰|ï¼\s*äº†\s*ï¼)\s*$", stripped):
            break
        if not stripped:
            # é€£ç¶šã—ãŸç©ºè¡Œã¯1ã¤ã«ã¾ã¨ã‚ã‚‹
            if result_lines and not prev_blank:
                result_lines.append("")
            prev_blank = True
            continue
        prev_blank = False
        result_lines.append(stripped)
        char_count += len(stripped)
        if char_count >= n:
            break
    result = "\n".join(result_lines).rstrip()
    return result[:n] + ("â€¦" if len(result) > n else "")


def make_summary(main_text: str, n: int) -> str:
    """é€šçŸ¥ã®æ¦‚è¦ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æœ¬æ–‡ã®è¦ç‚¹ã‚’æŠ½å‡ºï¼‰"""
    # ã€Œè¨˜ã€ä»¥é™ãŒã‚ã‚Œã°ãã®å†…å®¹ã‚’å„ªå…ˆï¼ˆæ—¥æœ¬ã®å…¬æ–‡æ›¸ã§ã¯ã€Œè¨˜ã€ãŒæœ¬æ–‡ã®å§‹ã¾ã‚Šã‚’ç¤ºã™ï¼‰
    ki_match = re.search(r"\n\s*è¨˜\s*\n", main_text)
    if ki_match:
        core = main_text[ki_match.end():].strip()
        return _format_summary(core, n)
    # ã‚¿ã‚¤ãƒˆãƒ«è¡Œï¼ˆã€Œã€œã«ã¤ã„ã¦ã€ç­‰ï¼‰ä»¥é™ã‚’æœ¬æ–‡ã¨ã—ã¦ä½¿ã†
    lines = main_text.splitlines()
    start = 0
    for i, line in enumerate(lines[:80]):
        s = line.strip()
        if re.search(r"ã«ã¤ã„ã¦|ã«é–¢ã™ã‚‹|ã«é–¢ã—ã¦|ã«ä¿‚ã‚‹", s) and 10 <= len(s) <= 200:
            start = i + 1
            break
    # ã‚¿ã‚¤ãƒˆãƒ«ç›´å¾Œã®ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œï¼ˆæ—¥ä»˜ãƒ»å®›å…ˆãƒ»ç™ºå‡ºè€…ãªã©ï¼‰ã‚’è¿½åŠ ã‚¹ã‚­ãƒƒãƒ—
    skip_end = min(len(lines), start + 15)
    while start < skip_end:
        s = lines[start].strip() if start < len(lines) else ""
        if not s or len(s) < 5 or any(re.search(p, s) for p in _HEADER_PATTERNS):
            start += 1
        else:
            break
    core = "\n".join(lines[start:]).strip()
    return _format_summary(core, n)

_ILLEGAL_CHARS_RE = re.compile(r"[\x00-\x08\x0b\x0c\x0e-\x1f]")

def _xls_safe(s) -> str:
    """Excelã«æ›¸ãè¾¼ã‚ãªã„åˆ¶å¾¡æ–‡å­—ã‚’é™¤å»ã™ã‚‹"""
    if not isinstance(s, str):
        return s
    return _ILLEGAL_CHARS_RE.sub("", s)

def write_excel_index(outdir: str, records: List[Record]):
    if not openpyxl: return

    # â”€â”€ è‰²å®šç¾© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    HEADER_BG   = PatternFill(fill_type="solid", fgColor="1E3A8A")   # æ¿ƒé’
    OK_BG       = PatternFill(fill_type="solid", fgColor="DCFCE7")   # è–„ç·‘
    REV_BG      = PatternFill(fill_type="solid", fgColor="FEE2E2")   # è–„èµ¤
    HEADER_FONT = Font(bold=True, color="FFFFFF", size=11)
    WRAP_CENTER = Alignment(horizontal="center", vertical="top", wrap_text=True)
    WRAP_LEFT   = Alignment(horizontal="left",   vertical="top", wrap_text=True)

    wb = openpyxl.Workbook()

    # â”€â”€ ã‚·ãƒ¼ãƒˆâ‘ : é€šçŸ¥ä¸€è¦§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ws = wb.active
    ws.title = "é€šçŸ¥ä¸€è¦§"

    headers = ["No.", "ã‚¿ã‚¤ãƒˆãƒ«(æ¨å®š)", "æ—¥ä»˜(æ¨å®š)", "ç™ºå‡ºè€…", "æ–½è¨­ã‚¿ã‚°", "æ¥­å‹™ã‚¿ã‚°", "çŠ¶æ…‹", "ç†ç”±", "æ¦‚è¦", "å…ƒãƒ•ã‚¡ã‚¤ãƒ«"]
    ws.append(headers)

    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®æ›¸å¼
    for col_idx in range(1, len(headers) + 1):
        cell = ws.cell(row=1, column=col_idx)
        cell.fill   = HEADER_BG
        cell.font   = HEADER_FONT
        cell.alignment = WRAP_CENTER
    ws.row_dimensions[1].height = 30

    # ãƒ‡ãƒ¼ã‚¿è¡Œ
    for seq, r in enumerate(records, start=1):
        status = "è¦ç¢ºèª" if r.needs_review else "æ­£å¸¸"
        summary_short = _xls_safe(r.summary[:400] if r.summary else "")
        ws.append([
            seq,
            _xls_safe(r.title_guess),
            _xls_safe(r.date_guess),
            _xls_safe(r.issuer_guess),
            " / ".join(r.tags_facility),
            " / ".join(r.tags_work),
            status,
            _xls_safe(r.reason),
            summary_short,
            _xls_safe(r.relpath),
        ])
        row_num = seq + 1
        fill = REV_BG if r.needs_review else OK_BG
        for col_idx in range(1, len(headers) + 1):
            cell = ws.cell(row=row_num, column=col_idx)
            cell.fill = fill
            cell.alignment = WRAP_LEFT
        # çŠ¶æ…‹åˆ—ã¯ã‚»ãƒ³ã‚¿ãƒªãƒ³ã‚°
        ws.cell(row=row_num, column=7).alignment = WRAP_CENTER
        # ã€Œè¦ç¢ºèªã€ã‚»ãƒ«ã¯èµ¤å­—ã§å¼·èª¿
        if r.needs_review:
            ws.cell(row=row_num, column=7).font = Font(bold=True, color="DC2626")

    # åˆ—å¹…ï¼ˆè¿‘ä¼¼å€¤ï¼‰
    col_widths = [6, 42, 20, 14, 24, 24, 8, 32, 55, 50]
    for i, w in enumerate(col_widths, 1):
        ws.column_dimensions[get_column_letter(i)].width = w

    # ãƒ•ãƒªãƒ¼ã‚ºã¨ã‚ªãƒ¼ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    ws.freeze_panes = "A2"
    ws.auto_filter.ref = ws.dimensions

    # â”€â”€ ã‚·ãƒ¼ãƒˆâ‘¡: ã‚µãƒãƒªãƒ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ws2 = wb.create_sheet("ã‚µãƒãƒªãƒ¼")
    ok_count  = sum(1 for r in records if not r.needs_review)
    rev_count = len(records) - ok_count

    def _s2_header(row, label):
        cell = ws2.cell(row=row, column=1, value=label)
        cell.font = Font(bold=True, color="FFFFFF")
        cell.fill = HEADER_BG
        cell.alignment = WRAP_CENTER

    ws2.append(["é›†è¨ˆé …ç›®", "ä»¶æ•°"])
    _s2_header(1, "é›†è¨ˆé …ç›®")
    ws2.cell(row=1, column=2).font   = HEADER_FONT
    ws2.cell(row=1, column=2).fill   = HEADER_BG
    ws2.cell(row=1, column=2).alignment = WRAP_CENTER

    ws2.append(["ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°", len(records)])
    ws2.append(["æ­£å¸¸æŠ½å‡º",     ok_count])
    ws2.append(["è¦ç¢ºèª",       rev_count])
    ws2.append([""])

    ws2.append(["æ–½è¨­ã‚¿ã‚°åˆ¥ä»¶æ•°", ""])
    _s2_header(ws2.max_row, "æ–½è¨­ã‚¿ã‚°åˆ¥ä»¶æ•°")
    tag_fac: Dict[str, int] = {}
    for r in records:
        for t in r.tags_facility:
            tag_fac[t] = tag_fac.get(t, 0) + 1
    for t, c in sorted(tag_fac.items(), key=lambda x: -x[1]):
        ws2.append([t, c])

    ws2.append([""])
    ws2.append(["æ¥­å‹™ã‚¿ã‚°åˆ¥ä»¶æ•°", ""])
    _s2_header(ws2.max_row, "æ¥­å‹™ã‚¿ã‚°åˆ¥ä»¶æ•°")
    tag_work: Dict[str, int] = {}
    for r in records:
        for t in r.tags_work:
            tag_work[t] = tag_work.get(t, 0) + 1
    for t, c in sorted(tag_work.items(), key=lambda x: -x[1]):
        ws2.append([t, c])

    ws2.append([""])
    ws2.append(["è¦ç¢ºèªã®ç†ç”±åˆ¥", ""])
    _s2_header(ws2.max_row, "è¦ç¢ºèªã®ç†ç”±åˆ¥")
    reason_counts: Dict[str, int] = {}
    for r in records:
        if r.needs_review and r.reason:
            reason_counts[r.reason] = reason_counts.get(r.reason, 0) + 1
    for reason, cnt in sorted(reason_counts.items(), key=lambda x: -x[1]):
        ws2.append([reason, cnt])

    ws2.column_dimensions["A"].width = 50
    ws2.column_dimensions["B"].width = 10

    excel_path = os.path.join(outdir, "00_çµ±åˆç›®æ¬¡.xlsx")
    try:
        wb.save(excel_path)
    except PermissionError:
        raise PermissionError("00_çµ±åˆç›®æ¬¡.xlsx ãŒä»–ã®ã‚¢ãƒ—ãƒªã§é–‹ã‹ã‚Œã¦ã„ã¾ã™ã€‚é–‰ã˜ã¦ã‹ã‚‰ã‚„ã‚Šç›´ã—ã¦ãã ã•ã„ã€‚")

def write_md_indices(outdir: str, records: List[Record]):
    with open(os.path.join(outdir, "00_çµ±åˆç›®æ¬¡.md"), "w", encoding="utf-8") as f:
        f.write("# çµ±åˆç›®æ¬¡ï¼ˆæ¦‚è¦ä»˜ãï¼‰\n\n")
        for r in records:
            f.write(f"- **{r.title_guess}**\n  - æ—¥ä»˜: {r.date_guess} / ç™ºå‡º: {r.issuer_guess}\n  - ã‚¿ã‚°: [{'/'.join(r.tags_facility)}] [{'/'.join(r.tags_work)}]\n  - æ¦‚è¦: {r.summary}\n  - å…ƒ: `{r.relpath}`\n\n")

def write_binded_texts(outdir: str, records: List[Record], limit_bytes: int):
    chunk_idx = 1
    current_size = 0
    current_blocks: List[str] = []
    current_toc: List[str] = []
    doc_num = 0

    def flush():
        nonlocal chunk_idx, current_size, current_blocks, current_toc
        if not current_blocks: return
        toc_header = (
            "ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®åéŒ²æ–‡æ›¸ä¸€è¦§ã€‘\n"
            + "\n".join(current_toc)
            + f"\nï¼ˆä»¥ä¸Š {len(current_toc)} ä»¶ï¼‰\n\n" + "=" * 60 + "\n"
        )
        with open(os.path.join(outdir, f"NotebookLMç”¨_çµ±åˆãƒ‡ãƒ¼ã‚¿_{chunk_idx:02d}.txt"), "w", encoding="utf-8") as f:
            f.write(toc_header + "\n".join(current_blocks))
        chunk_idx += 1
        current_size = 0
        current_blocks = []
        current_toc = []

    for r in records:
        if not r.full_text_for_bind.strip(): continue
        doc_num += 1
        toc_entry = f"  {doc_num:3d}. {r.title_guess}ï¼ˆ{r.date_guess or 'æ—¥ä»˜ä¸æ˜'}ï¼‰"
        block = (
            f"\n\n{'='*60}\n"
            f"ã€æ–‡æ›¸ No.{doc_num}ã€‘\n"
            f"å…ƒãƒ•ã‚¡ã‚¤ãƒ«: {r.relpath}\n"
            f"ã‚¿ã‚¤ãƒˆãƒ«: {r.title_guess}\n"
            f"æ—¥ä»˜: {r.date_guess or 'ä¸æ˜'} / ç™ºå‡º: {r.issuer_guess or 'ä¸æ˜'}\n"
            f"{'-'*60}\n"
            f"{r.full_text_for_bind}\n"
            f"{'='*60}\n\n"
        )
        b_len = len(block.encode("utf-8"))
        if current_size + b_len > limit_bytes and current_size > 0: flush()
        current_blocks.append(block)
        current_toc.append(toc_entry)
        current_size += b_len
    flush()

def compute_sha1(path: str) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®SHA1ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—ã—ã¦é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºã«ä½¿ã†"""
    h = hashlib.sha1()
    try:
        with open(get_safe_path(path), "rb") as f:
            for chunk in iter(lambda: f.read(65536), b""):
                h.update(chunk)
        return h.hexdigest()
    except Exception:
        return ""

def extract_txt(path: str) -> Tuple[str, str]:
    """ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆæ–‡å­—ã‚³ãƒ¼ãƒ‰ã‚’è‡ªå‹•åˆ¤å®šï¼‰"""
    for enc in ("utf-8-sig", "cp932", "utf-8", "latin-1"):
        try:
            with open(get_safe_path(path), "r", encoding=enc, errors="ignore") as f:
                return f.read(), "txt_read"
        except Exception:
            continue
    return "", "txt_err"

def extract_csv(path: str) -> Tuple[str, str]:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’Markdownè¡¨å½¢å¼ã«æ•´å½¢ã™ã‚‹"""
    for enc in ("utf-8-sig", "cp932", "utf-8"):
        try:
            with open(get_safe_path(path), "r", encoding=enc, newline="", errors="ignore") as f:
                rows = list(csv.reader(f))
            if not rows:
                return "", "csv_empty"
            out = []
            for row in rows[:400]:
                if any(c.strip() for c in row):
                    out.append("| " + " | ".join([c.strip().replace("\n", " ") for c in row]) + " |")
            return "\n".join(out), "csv_md"
        except Exception:
            continue
    return "", "csv_err"

def write_html_report(outdir: str, records: List[Record]):
    """äººé–“ãŒè¦‹ã‚„ã™ã„HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ãã ã‘ã§OKï¼‰"""
    def esc(s: object) -> str:
        return _html.escape(str(s) if s is not None else "")

    total       = len(records)
    ok_count    = sum(1 for r in records if not r.needs_review)
    needs_rev_count = total - ok_count
    ok_pct      = round(ok_count    / total * 100) if total else 0
    rev_pct     = round(needs_rev_count / total * 100) if total else 0

    # â”€â”€â”€ ãƒ•ã‚¡ã‚¤ãƒ«ç¨®åˆ¥é›†è¨ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ext_label_map = {
        ".pdf": "PDF", ".docx": "Word",
        ".xlsx": "Excel", ".xlsm": "Excel", ".xls": "Excel",
        ".xdw": "DocuWorks", ".xbd": "DocuWorks",
        ".txt": "ãƒ†ã‚­ã‚¹ãƒˆ", ".csv": "CSV",
    }
    ext_counts: Dict[str, int] = {}
    for r in records:
        lbl = ext_label_map.get(r.ext.lower(), f"ãã®ä»–({r.ext})")
        ext_counts[lbl] = ext_counts.get(lbl, 0) + 1
    ext_breakdown_parts = [
        f'<span class="type-chip">{esc(lbl)} <b>{cnt}</b>ä»¶</span>'
        for lbl, cnt in sorted(ext_counts.items(), key=lambda x: -x[1])
    ]
    ext_breakdown_html = "".join(ext_breakdown_parts)

    # â”€â”€â”€ æŠ½å‡ºæ–¹å¼é›†è¨ˆï¼ˆæŠ½å‡ºæ–¹å¼åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    method_counts: Dict[str, int] = {}
    for r in records:
        method_counts[r.method] = method_counts.get(r.method, 0) + 1
    method_rows = "".join(
        f"<tr><td>{esc(m)}</td><td class='mcnt'>{c}</td></tr>"
        for m, c in sorted(method_counts.items(), key=lambda x: -x[1])
    )

    # â”€â”€â”€ è¦ç¢ºèªã®ä¸»è¦ç†ç”±ã‚’é›†è¨ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    review_reasons: Dict[str, int] = {}
    for r in records:
        if r.needs_review and r.reason:
            key = r.reason[:35] + ("â€¦" if len(r.reason) > 35 else "")
            review_reasons[key] = review_reasons.get(key, 0) + 1
    review_reason_rows = "".join(
        f'<li><span class="rr-count">{c}ä»¶</span> {esc(k)}</li>'
        for k, c in sorted(review_reasons.items(), key=lambda x: -x[1])[:5]
    )

    # â”€â”€â”€ ãƒãƒƒã‚¸è‰² â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    FAC_COLOR  = "#2563eb"
    WORK_COLOR = "#16a34a"
    def make_badge(text: str, color: str) -> str:
        return f'<span class="badge" style="background:{color}">{esc(text)}</span>'

    # â”€â”€â”€ TOCã‚¢ã‚¤ãƒ†ãƒ ç”Ÿæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    toc_items_html: List[str] = []
    for idx, r in enumerate(records):
        toc_cls  = "toc-review" if r.needs_review else "toc-ok"
        toc_icon = "âš " if r.needs_review else "âœ“"
        short_t  = r.title_guess[:28] + ("â€¦" if len(r.title_guess) > 28 else "")
        d_str    = r.date_guess or "æ—¥ä»˜ä¸æ˜"
        tsearch  = (r.title_guess + " " + d_str).lower().replace('"', "")
        toc_items_html.append(
            f'<a href="#card-{idx}" class="toc-item {toc_cls}" data-search="{esc(tsearch)}">'
            f'<span class="toc-icon">{toc_icon}</span>'
            f'<span class="toc-body">'
            f'<span class="toc-num">{idx + 1}.</span>'
            f'<span class="toc-title">{esc(short_t)}</span>'
            f'<span class="toc-date">{esc(d_str)}</span>'
            f'</span></a>'
        )

    # â”€â”€â”€ ã‚«ãƒ¼ãƒ‰ç”Ÿæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    cards_html: List[str] = []
    for idx, r in enumerate(records):
        card_cls  = "card-review" if r.needs_review else "card-ok"
        rev_badge = '<span class="rev-badge">âš  è¦ç¢ºèª</span>' if r.needs_review else \
                    '<span class="ok-badge">âœ“ æ­£å¸¸</span>'
        fac_badges  = "".join(make_badge(t, FAC_COLOR)  for t in r.tags_facility)
        work_badges = "".join(make_badge(t, WORK_COLOR) for t in r.tags_work)
        tags_html   = (fac_badges + work_badges) or \
                      '<span style="color:#94a3b8;font-size:12px">ã‚¿ã‚°ãªã—</span>'
        date_str   = esc(r.date_guess)   or "æ—¥ä»˜ä¸æ˜"
        issuer_str = esc(r.issuer_guess) or "ç™ºå‡ºè€…ä¸æ˜"
        pages_str  = f"/{r.pages}p" if r.pages else ""
        size_kb    = f"{r.size // 1024:,} KB" if r.size >= 1024 else f"{r.size} B"
        reason_html = (
            f'<div class="reason-box">âš  {esc(r.reason)}</div>' if r.reason else ""
        )
        search_data = " ".join([
            r.title_guess, r.summary, r.relpath,
            r.date_guess, r.issuer_guess,
            " ".join(r.tags_facility), " ".join(r.tags_work),
            r.reason, r.method,
        ]).replace('"', '')
        summary_html = (esc(r.summary)
                        or '<i style="color:#94a3b8">æœ¬æ–‡ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ</i>')
        cards_html.append(f"""
<div id="card-{idx}" class="card {card_cls}" data-search="{esc(search_data.lower())}">
  <div class="card-header">
    <div class="card-title">{esc(r.title_guess)}</div>
    {rev_badge}
  </div>
  <div class="meta">
    <span>ğŸ“… {date_str}</span>
    <span>ğŸ¢ {issuer_str}</span>
    <span>ğŸ“„ {esc(r.ext.upper().lstrip('.'))}{pages_str} Â· {size_kb}</span>
    <span class="method-tag">æŠ½å‡º: {esc(r.method)}</span>
  </div>
  <div class="tags">{tags_html}</div>
  <div class="summary">{summary_html}</div>
  <div class="filepath">ğŸ“ {esc(r.relpath)}</div>
  {reason_html}
</div>""")

    gen_time = time.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')

    html_content = f"""<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0">
<title>NoticeForge å‡¦ç†ãƒ¬ãƒãƒ¼ãƒˆ</title>
<style>
*{{box-sizing:border-box;margin:0;padding:0}}
body{{font-family:'Meiryo UI','Yu Gothic UI','Hiragino Sans',sans-serif;background:#f1f5f9;color:#1e293b;font-size:14px}}

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆæ–‡æ›¸ç›®æ¬¡ï¼‰
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
.toc-sidebar{{
  position:fixed;left:0;top:0;width:252px;height:100vh;
  background:#0f172a;color:#e2e8f0;
  display:flex;flex-direction:column;z-index:200;
  border-right:1px solid #1e3a5f;
}}
.toc-head{{
  padding:14px 16px;font-size:14px;font-weight:bold;
  background:#1e3a8a;color:white;
  display:flex;align-items:center;gap:8px;flex-shrink:0;
}}
.toc-summary-row{{
  padding:8px 16px;font-size:12px;color:#94a3b8;
  background:#1e293b;border-bottom:1px solid #334155;flex-shrink:0;
  display:flex;gap:14px;
}}
.toc-ok-sum{{color:#4ade80;font-weight:bold}}
.toc-rev-sum{{color:#f87171;font-weight:bold}}
.toc-filter-wrap{{
  padding:8px 12px;background:#1e293b;
  border-bottom:1px solid #334155;flex-shrink:0;
}}
.toc-filter{{
  width:100%;padding:6px 10px;border-radius:6px;
  border:1px solid #334155;background:#0f172a;
  color:#e2e8f0;font-size:12px;font-family:inherit;outline:none;
}}
.toc-filter:focus{{border-color:#3b82f6}}
.toc-nav{{flex:1;overflow-y:auto;padding:4px 0}}
.toc-nav::-webkit-scrollbar{{width:4px}}
.toc-nav::-webkit-scrollbar-thumb{{background:#334155;border-radius:2px}}
.toc-item{{
  display:flex;align-items:flex-start;gap:8px;
  padding:7px 14px;text-decoration:none;color:#cbd5e1;
  font-size:12px;line-height:1.4;
  border-left:3px solid transparent;
  transition:background .15s,border-color .15s;
}}
.toc-item:hover{{background:#1e293b;color:white}}
.toc-item.active{{background:#1e3a8a;border-left-color:#60a5fa;color:white}}
.toc-icon{{font-size:11px;flex-shrink:0;margin-top:1px;width:14px;text-align:center}}
.toc-ok   .toc-icon{{color:#4ade80}}
.toc-review .toc-icon{{color:#f87171}}
.toc-body{{display:flex;flex-direction:column;min-width:0;flex:1}}
.toc-num{{color:#64748b;font-size:10px}}
.toc-title{{font-size:12px;color:inherit;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}}
.toc-date{{font-size:10px;color:#64748b;margin-top:1px}}
.toc-item.toc-hidden{{display:none}}
.toc-empty{{padding:16px;font-size:12px;color:#475569;text-align:center}}

/* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• */
.main-wrapper{{margin-left:252px}}

/* â”€â”€â”€ ãƒšãƒ¼ã‚¸ãƒ˜ãƒƒãƒ€ãƒ¼ â”€â”€â”€ */
.page-header{{
  background:linear-gradient(135deg,#1e40af,#2563eb);
  color:white;padding:20px 32px;
  display:flex;justify-content:space-between;align-items:flex-end;
  flex-wrap:wrap;gap:8px;
}}
.page-header h1{{font-size:22px;font-weight:bold}}
.page-header .sub{{opacity:.75;font-size:12px;margin-top:4px}}

/* â”€â”€â”€ å‡¦ç†æ¦‚è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ â”€â”€â”€ */
.overview-section{{
  background:white;border-bottom:1px solid #e2e8f0;padding:20px 32px 16px;
}}
.overview-title{{
  font-size:13px;font-weight:bold;color:#64748b;
  text-transform:uppercase;letter-spacing:.05em;margin-bottom:14px;
}}
.stats-row{{display:flex;gap:12px;flex-wrap:wrap;margin-bottom:16px;align-items:stretch}}
.stat-box{{
  background:#f8fafc;border:1px solid #e2e8f0;border-radius:10px;
  padding:14px 24px;text-align:center;min-width:110px;
}}
.stat-box .num{{font-size:30px;font-weight:bold;color:#1e40af;line-height:1}}
.stat-box .lbl{{font-size:11px;color:#64748b;margin-top:6px}}
.stat-box .pct{{font-size:11px;color:#94a3b8;margin-top:2px}}
.stat-box.warn .num{{color:#dc2626}}
.stat-box.good .num{{color:#16a34a}}
.overview-bottom{{display:flex;gap:24px;flex-wrap:wrap;align-items:flex-start}}
.type-section{{flex:1;min-width:200px}}
.type-label{{font-size:12px;color:#64748b;font-weight:bold;margin-bottom:8px}}
.type-chips{{display:flex;gap:8px;flex-wrap:wrap}}
.type-chip{{
  background:#f1f5f9;border:1px solid #e2e8f0;border-radius:20px;
  padding:4px 12px;font-size:12px;color:#475569;
}}
.type-chip b{{color:#1e40af}}
.method-section{{flex:1;min-width:180px}}
.method-section table{{font-size:12px;border-collapse:collapse;width:100%}}
.method-section td{{padding:3px 8px;border-bottom:1px solid #f1f5f9;color:#475569}}
.method-section td.mcnt{{text-align:right;font-weight:bold;color:#1e40af}}
.method-section tr:last-child td{{border-bottom:none}}
.review-section{{flex:1;min-width:180px}}
.review-reasons{{list-style:none;font-size:12px;color:#92400e}}
.review-reasons li{{padding:2px 0;display:flex;align-items:baseline;gap:6px}}
.rr-count{{
  background:#fee2e2;color:#dc2626;border-radius:4px;
  padding:1px 6px;font-weight:bold;font-size:11px;white-space:nowrap;flex-shrink:0;
}}
.guide-box{{
  background:#eff6ff;border:1px solid #bfdbfe;border-radius:8px;
  padding:10px 16px;font-size:12px;color:#1e40af;margin-top:14px;
  display:flex;align-items:flex-start;gap:8px;
}}
.guide-box strong{{font-weight:bold}}

/* â”€â”€â”€ æ¤œç´¢ãƒãƒ¼ï¼ˆstickyï¼‰â”€â”€â”€ */
.search-bar{{
  background:white;padding:10px 24px;border-bottom:1px solid #e2e8f0;
  display:flex;align-items:center;gap:10px;
  position:sticky;top:0;z-index:100;
  box-shadow:0 2px 6px rgba(0,0,0,.06);
}}
.search-input{{
  flex:1;max-width:680px;padding:9px 14px 9px 40px;
  border:2px solid #e2e8f0;border-radius:8px;
  font-size:13px;font-family:inherit;outline:none;
  transition:border-color .2s;
  background:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='16' height='16' fill='none' stroke='%2394a3b8' stroke-width='2' viewBox='0 0 24 24'%3E%3Ccircle cx='11' cy='11' r='8'/%3E%3Cpath d='m21 21-4.35-4.35'/%3E%3C/svg%3E") no-repeat 12px center;
}}
.search-input:focus{{border-color:#2563eb}}
.search-hint{{font-size:11px;color:#94a3b8}}
.search-count{{font-size:13px;color:#64748b;font-weight:bold;white-space:nowrap;margin-left:auto}}
.no-results{{text-align:center;padding:64px 16px;color:#94a3b8;font-size:15px;display:none}}

/* â”€â”€â”€ ã‚«ãƒ¼ãƒ‰ â”€â”€â”€ */
.container{{max-width:1000px;margin:20px auto;padding:0 20px}}
.card{{
  background:white;border-radius:10px;padding:18px 22px;margin-bottom:14px;
  border-left:5px solid #94a3b8;
  box-shadow:0 1px 4px rgba(0,0,0,.07);
  transition:box-shadow .2s;scroll-margin-top:56px;
}}
.card:hover{{box-shadow:0 3px 10px rgba(0,0,0,.12)}}
.card.highlight{{outline:3px solid #3b82f6;outline-offset:2px}}
.card-ok{{border-left-color:#16a34a}}
.card-review{{border-left-color:#dc2626}}
.card-header{{display:flex;justify-content:space-between;align-items:flex-start;gap:12px;margin-bottom:10px}}
.card-title{{font-size:15px;font-weight:bold;color:#0f172a;line-height:1.5;flex:1}}
.ok-badge{{background:#dcfce7;color:#16a34a;border:1px solid #86efac;border-radius:6px;padding:2px 10px;font-size:12px;font-weight:bold;white-space:nowrap}}
.rev-badge{{background:#fee2e2;color:#dc2626;border:1px solid #fca5a5;border-radius:6px;padding:2px 10px;font-size:12px;font-weight:bold;white-space:nowrap}}
.meta{{display:flex;gap:14px;flex-wrap:wrap;color:#64748b;font-size:12px;margin-bottom:10px}}
.method-tag{{color:#94a3b8;font-size:11px}}
.tags{{display:flex;gap:6px;flex-wrap:wrap;margin-bottom:12px}}
.badge{{color:white;padding:2px 10px;border-radius:12px;font-size:12px;font-weight:500}}
.summary{{
  background:#f8fafc;border:1px solid #e2e8f0;border-radius:6px;
  padding:10px 14px;font-size:13px;line-height:1.8;color:#334155;
  max-height:160px;overflow-y:auto;margin-bottom:10px;white-space:pre-wrap;
}}
.filepath{{font-size:11px;color:#94a3b8;font-family:'Consolas','Courier New',monospace;word-break:break-all}}
.reason-box{{margin-top:8px;font-size:12px;color:#92400e;background:#fffbeb;border:1px solid #fde68a;border-radius:5px;padding:6px 12px}}

/* â”€â”€â”€ ãƒ•ãƒƒã‚¿ãƒ¼ â”€â”€â”€ */
.footer{{text-align:center;color:#94a3b8;font-size:11px;padding:24px;margin-top:8px}}

/* â”€â”€â”€ ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ï¼ˆç‹­ã„ç”»é¢ã§ã¯ç›®æ¬¡éè¡¨ç¤ºï¼‰ â”€â”€â”€ */
@media(max-width:900px){{
  .toc-sidebar{{display:none}}
  .main-wrapper{{margin-left:0}}
}}
</style>
</head>
<body>

<!-- â•â•â•â• å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆæ–‡æ›¸ç›®æ¬¡ï¼‰â•â•â•â• -->
<aside class="toc-sidebar">
  <div class="toc-head">ğŸ“‹ æ–‡æ›¸ç›®æ¬¡</div>
  <div class="toc-summary-row">
    <span class="toc-ok-sum">âœ“ æ­£å¸¸ {ok_count}ä»¶</span>
    <span class="toc-rev-sum">âš  è¦ç¢ºèª {needs_rev_count}ä»¶</span>
  </div>
  <div class="toc-filter-wrap">
    <input class="toc-filter" id="tocFilter" type="text"
      placeholder="ç›®æ¬¡ã‚’çµã‚Šè¾¼ã‚€â€¦" oninput="filterToc()">
  </div>
  <nav class="toc-nav" id="tocNav">
    {''.join(toc_items_html)}
    <div class="toc-empty" id="tocEmpty" style="display:none">è©²å½“ãªã—</div>
  </nav>
</aside>

<!-- â•â•â•â• ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ â•â•â•â• -->
<div class="main-wrapper">

  <!-- ãƒšãƒ¼ã‚¸ãƒ˜ãƒƒãƒ€ãƒ¼ -->
  <header class="page-header">
    <div>
      <h1>NoticeForge å‡¦ç†ãƒ¬ãƒãƒ¼ãƒˆ</h1>
      <div class="sub">ç”Ÿæˆæ—¥æ™‚: {gen_time}</div>
    </div>
  </header>

  <!-- å‡¦ç†æ¦‚è¦ -->
  <section class="overview-section">
    <div class="overview-title">å‡¦ç†æ¦‚è¦</div>
    <div class="stats-row">
      <div class="stat-box">
        <div class="num">{total}</div>
        <div class="lbl">ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°</div>
      </div>
      <div class="stat-box good">
        <div class="num">{ok_count}</div>
        <div class="lbl">æ­£å¸¸æŠ½å‡º</div>
        <div class="pct">{ok_pct}%</div>
      </div>
      <div class="stat-box warn">
        <div class="num">{needs_rev_count}</div>
        <div class="lbl">è¦ç¢ºèª</div>
        <div class="pct">{rev_pct}%</div>
      </div>
    </div>
    <div class="overview-bottom">
      <div class="type-section">
        <div class="type-label">ãƒ•ã‚¡ã‚¤ãƒ«ç¨®åˆ¥</div>
        <div class="type-chips">{ext_breakdown_html}</div>
      </div>
      <div class="method-section">
        <div class="type-label">æŠ½å‡ºæ–¹å¼åˆ¥</div>
        <table><tbody>{method_rows}</tbody></table>
      </div>
      {'<div class="review-section"><div class="type-label">è¦ç¢ºèªã®ä¸»ãªç†ç”±</div><ul class="review-reasons">' + review_reason_rows + '</ul></div>' if review_reason_rows else ''}
    </div>
    <div class="guide-box">
      ğŸ’¡ <span><strong>NotebookLMã¸ã®å…¥åŠ›ï¼š</strong>
      å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ã€Œ00_çµ±åˆç›®æ¬¡.mdã€ã¨ã€ŒNotebookLMç”¨_çµ±åˆãƒ‡ãƒ¼ã‚¿_â—‹â—‹.txtã€ã‚’
      NotebookLMã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚
      ã€Œè¦ç¢ºèªã€ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç›®æ¬¡ã«å«ã¾ã‚Œã¾ã™ãŒã€æœ¬æ–‡ã®ç²¾åº¦ãŒä½ã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚</span>
    </div>
  </section>

  <!-- æ¤œç´¢ãƒãƒ¼ï¼ˆstickyï¼‰-->
  <div class="search-bar">
    <input class="search-input" id="searchInput" type="text"
      placeholder="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§çµã‚Šè¾¼ã‚€ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãƒ»ç™ºå‡ºè€…ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«åãƒ»æ¦‚è¦ãªã©ã€‚NotebookLMã®å¼•ç”¨æ–‡ã‚’ãã®ã¾ã¾è²¼ã‚Šä»˜ã‘ã¦ã‚‚OKï¼‰"
      oninput="filterCards()">
    <span class="search-hint">â†’ å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç´ æ—©ãç‰¹å®šã§ãã¾ã™</span>
    <span class="search-count" id="searchCount"></span>
  </div>

  <!-- ã‚«ãƒ¼ãƒ‰ä¸€è¦§ -->
  <div class="container">
    {''.join(cards_html)}
    <div class="no-results" id="noResults">
      è©²å½“ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è©¦ã—ã¦ãã ã•ã„ã€‚
    </div>
  </div>

  <div class="footer">NoticeForge &mdash; NotebookLM é€£æºãƒ„ãƒ¼ãƒ« &nbsp;|&nbsp; ç”Ÿæˆ: {gen_time}</div>
</div>

<script>
/* â”€â”€ ã‚«ãƒ¼ãƒ‰æ¤œç´¢ â”€â”€ */
function filterCards() {{
  var q = document.getElementById('searchInput').value.toLowerCase();
  var cards = document.querySelectorAll('.card');
  var shown = 0;
  cards.forEach(function(card) {{
    var match = !q || card.getAttribute('data-search').includes(q);
    card.style.display = match ? '' : 'none';
    if (match) shown++;
  }});
  var countEl = document.getElementById('searchCount');
  var noRes   = document.getElementById('noResults');
  countEl.textContent = q ? (shown + ' ä»¶ / ' + cards.length + ' ä»¶ä¸­') : (cards.length + ' ä»¶');
  noRes.style.display  = (q && shown === 0) ? 'block' : 'none';
}}

/* â”€â”€ ç›®æ¬¡çµã‚Šè¾¼ã¿ â”€â”€ */
function filterToc() {{
  var q = document.getElementById('tocFilter').value.toLowerCase();
  var items = document.querySelectorAll('.toc-item');
  var shown = 0;
  items.forEach(function(a) {{
    var match = !q || a.getAttribute('data-search').includes(q);
    a.classList.toggle('toc-hidden', !match);
    if (match) shown++;
  }});
  document.getElementById('tocEmpty').style.display = (q && shown === 0) ? 'block' : 'none';
}}

/* â”€â”€ ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«é€£å‹•ã§TOCã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ â”€â”€ */
(function() {{
  var tocItems = {{}};
  document.querySelectorAll('.toc-item').forEach(function(a) {{
    var id = a.getAttribute('href').slice(1);
    tocItems[id] = a;
  }});
  var observer = new IntersectionObserver(function(entries) {{
    entries.forEach(function(entry) {{
      if (entry.isIntersecting) {{
        Object.values(tocItems).forEach(function(a) {{ a.classList.remove('active'); }});
        var active = tocItems[entry.target.id];
        if (active) {{
          active.classList.add('active');
          var nav = document.getElementById('tocNav');
          if (nav) {{
            var offset = active.offsetTop - nav.offsetTop;
            nav.scrollTop = offset - nav.clientHeight / 3;
          }}
        }}
      }}
    }});
  }}, {{ rootMargin: '-5% 0% -70% 0%', threshold: 0 }});
  document.querySelectorAll('.card').forEach(function(c) {{ observer.observe(c); }});

  /* â”€â”€ åˆæœŸä»¶æ•°è¡¨ç¤º â”€â”€ */
  document.getElementById('searchCount').textContent =
    document.querySelectorAll('.card').length + ' ä»¶';

  /* â”€â”€ TOCãƒªãƒ³ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ãŸã¨ãã‚«ãƒ¼ãƒ‰ã‚’ä¸€ç¬ãƒã‚¤ãƒ©ã‚¤ãƒˆ â”€â”€ */
  document.querySelectorAll('.toc-item').forEach(function(a) {{
    a.addEventListener('click', function() {{
      var id = a.getAttribute('href').slice(1);
      var card = document.getElementById(id);
      if (card) {{
        card.classList.add('highlight');
        setTimeout(function() {{ card.classList.remove('highlight'); }}, 1200);
      }}
    }});
  }});
}})();
</script>
</body>
</html>"""

    with open(os.path.join(outdir, "00_äººé–“ç”¨ãƒ¬ãƒãƒ¼ãƒˆ.html"), "w", encoding="utf-8") as f:
        f.write(html_content)


def process_folder(indir: str, outdir: str, cfg: Dict[str, object], progress_callback: Optional[Callable[[int, int, str, str], None]] = None, stop_event=None) -> Tuple[int, int, str]:
    os.makedirs(outdir, exist_ok=True)
    outdir_abs = os.path.abspath(outdir)

    # å‰å›ã®ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ï¼ˆå¤ã„ãƒ‡ãƒ¼ã‚¿ãŒNotebookLMã«æ··å…¥ã—ãªã„ã‚ˆã†ã«ï¼‰
    # â€» 00_manifest.json ã ã‘ã¯å·®åˆ†å‡¦ç†ã®ãŸã‚ã«æ®‹ã™
    for fname in os.listdir(outdir):
        if fname.startswith("NotebookLMç”¨_çµ±åˆãƒ‡ãƒ¼ã‚¿_") and fname.endswith(".txt"):
            try: os.remove(os.path.join(outdir, fname))
            except Exception: pass
    for fname in ("00_çµ±åˆç›®æ¬¡.md", "00_çµ±åˆç›®æ¬¡.xlsx", "00_äººé–“ç”¨ãƒ¬ãƒãƒ¼ãƒˆ.html", "00_å‡¦ç†ãƒ­ã‚°.txt"):
        p = os.path.join(outdir, fname)
        if os.path.exists(p):
            try: os.remove(p)
            except Exception: pass

    max_depth = int(cfg.get("max_depth", 30))
    split_kws = list(cfg.get("main_attach_split_keywords", []))
    min_chars = int(cfg.get("min_chars_mainbody", 400))
    use_ocr = bool(cfg.get("use_ocr", False))
    limit_bytes = int(cfg.get("bind_bytes_limit", 15000000))

    SKIP_FILENAMES = frozenset({"thumbs.db", "desktop.ini", ".ds_store"})
    SKIP_EXTENSIONS = frozenset({".db", ".tmp", ".bak", ".lnk", ".ini", ".cache"})

    # ã€ãƒã‚°ä¿®æ­£ã€‘å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ãŒå…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€å†…ã«ã‚ã‚‹å ´åˆã€ã‚¹ã‚­ãƒ£ãƒ³å¯¾è±¡ã‹ã‚‰é™¤å¤–ã™ã‚‹
    targets: List[str] = []
    for root, dirs, files in os.walk(indir):
        # å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ã‚µãƒ–ãƒ„ãƒªãƒ¼ã‚’ä¸¸ã”ã¨ã‚¹ã‚­ãƒƒãƒ—ï¼ˆdirs ã‚’ in-place å¤‰æ›´ï¼‰
        dirs[:] = [
            d for d in dirs
            if os.path.abspath(os.path.join(root, d)) != outdir_abs
        ]
        # æ·±ã•åˆ¶é™
        rel_root = os.path.relpath(root, indir)
        depth = 0 if rel_root == "." else rel_root.count(os.sep) + 1
        if depth >= max_depth:
            dirs.clear()
            continue
        for fn in files:
            if fn.lower() in SKIP_FILENAMES: continue
            if os.path.splitext(fn)[1].lower() in SKIP_EXTENSIONS: continue
            if fn.startswith("~$"): continue
            targets.append(os.path.join(root, fn))

    total_files = len(targets)
    records: List[Record] = []
    seen_sha1: set = set()
    skipped_dup = 0
    skipped_cache = 0

    # ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆï¼ˆå‡¦ç†ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰ã‚’èª­ã¿è¾¼ã‚€
    # â†’ å¤‰æ›´ã®ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å†å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã€å‰å›çµæœã‚’å†åˆ©ç”¨ã™ã‚‹
    manifest_path = os.path.join(outdir, "00_manifest.json")
    manifest: Dict[str, dict] = {}
    if os.path.exists(manifest_path):
        try:
            with open(manifest_path, "r", encoding="utf-8") as f:
                manifest = json.load(f)
        except Exception:
            manifest = {}

    log_lines: List[str] = [
        "=== NoticeForge å‡¦ç†ãƒ­ã‚° ===",
        f"å‡¦ç†æ—¥æ™‚: {time.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}",
        f"å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€: {indir}",
        f"å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {outdir}",
        f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­è¾¼: {len(manifest)} ä»¶",
        "",
        "--- å„ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†çµæœ ---",
    ]

    for i, path in enumerate(targets):
        # åœæ­¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãƒã‚§ãƒƒã‚¯
        if stop_event and stop_event.is_set():
            log_lines.append("[STOPPED] ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šå‡¦ç†ã‚’é€”ä¸­ã§åœæ­¢ã—ã¾ã—ãŸã€‚")
            break

        rel = os.path.relpath(path, indir)
        ext = os.path.splitext(path)[1].lower()
        if progress_callback: progress_callback(i + 1, total_files, rel, "(ç¢ºèªä¸­...)")

        sha1 = compute_sha1(path)

        # é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
        if sha1 and sha1 in seen_sha1:
            if progress_callback: progress_callback(i + 1, total_files, rel, "(é‡è¤‡ãƒ»ã‚¹ã‚­ãƒƒãƒ—)")
            log_lines.append(f"[é‡è¤‡ã‚¹ã‚­ãƒƒãƒ—] {rel}")
            skipped_dup += 1
            continue

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆãƒã‚§ãƒƒã‚¯ï¼ˆSHA1ãŒä¸€è‡´ â†’ å†…å®¹å¤‰æ›´ãªã— â†’ å‰å›çµæœã‚’å†åˆ©ç”¨ï¼‰
        if sha1 and sha1 in manifest:
            try:
                cached = manifest[sha1]
                record = Record(**{**cached, "relpath": rel, "sha1": sha1})
                records.append(record)
                seen_sha1.add(sha1)
                if progress_callback: progress_callback(i + 1, total_files, rel, "(ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨)")
                log_lines.append(f"[ã‚­ãƒ£ãƒƒã‚·ãƒ¥] {rel}")
                skipped_cache += 1
                continue
            except Exception:
                pass  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå£Šã‚Œã¦ã„ãŸã‚‰é€šå¸¸å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

        seen_sha1.add(sha1)
        if progress_callback: progress_callback(i + 1, total_files, rel, "(æŠ½å‡ºä¸­...)")

        text, method, reason, pages = "", "unhandled", "", None

        try:
            if ext == ".pdf":
                if use_ocr and progress_callback: progress_callback(i + 1, total_files, rel, "(OCRå‡¦ç†ä¸­...æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™)")
                text, pages, method = extract_pdf(path, use_ocr)
            elif ext == ".docx":
                text, method = extract_docx(path)
            elif ext in (".xlsx", ".xlsm", ".xls"):
                text, method = extract_excel(path)
            elif ext in (".xdw", ".xbd"):
                text, method = extract_xdw(path)
            elif ext == ".txt":
                text, method = extract_txt(path)
            elif ext == ".csv":
                text, method = extract_csv(path)
        except Exception as e:
            method, reason = "error", f"æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e.__class__.__name__}"

        text = convert_japanese_year(text)
        main, attach = split_main_attach(text, split_kws)
        title = guess_title(main or text, os.path.basename(path))
        date_guess = guess_date(text)
        issuer_guess = guess_issuer(text)
        fac, work, ev = tag_text(main or text)

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’å–å¾—ï¼ˆneeds_reviewåˆ¤å®šã§ä½¿ç”¨ï¼‰
        file_size = os.path.getsize(get_safe_path(path))
        text_len = len(main or text)

        needs_rev = False
        if method in ("unhandled", "error") or "missing" in method:
            # æŠ½å‡ºæ–¹æ³•ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãƒ»å¤±æ•—ã—ãŸå ´åˆ
            needs_rev = True
            if not reason:
                if "xdw2text_missing" in method:
                    reason = "DocuWorksãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ãŸã‚èª­å–ä¸å¯ï¼ˆxdw2text.exe ã¾ãŸã¯ xdoc2txt.exe ãŒå¿…è¦: https://ebstudio.info/home/xdoc2txt.htmlï¼‰"
                elif method == "unhandled":
                    reason = f"æœªå¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ ({ext})"
                elif "pymupdf_missing" in method:
                    reason = "PyMuPDFãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆpip install PyMuPDFï¼‰"
                elif "excel_lib_missing" in method:
                    reason = "Excelãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆpip install openpyxl xlrdï¼‰"
                else:
                    reason = f"æŠ½å‡ºå¤±æ•—: {method}"
        elif ext in (".xlsx", ".xlsm", ".xls", ".csv", ".txt"):
            # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆãƒ»ãƒ†ã‚­ã‚¹ãƒˆã¯æŠ½å‡ºæˆåŠŸãªã‚‰æ–‡å­—æ•°ä¸å•ã§æ­£å¸¸ã¨ã¿ãªã™
            pass
        elif text_len < 30:
            # 30æ–‡å­—æœªæº€ã¯ç¢ºå®Ÿã«æŠ½å‡ºå¤±æ•—ã¾ãŸã¯å®Œå…¨ãªç”»åƒPDF
            needs_rev = True
            if ext == ".pdf" and not TESSERACT_AVAILABLE:
                reason = "ç”»åƒPDFã®å¯èƒ½æ€§ï¼ˆTesseract OCRãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã®ãŸã‚èª­å–ä¸å¯ï¼‰"
            elif ext == ".pdf":
                reason = "OCRã‚’è©¦ã¿ã¾ã—ãŸãŒèª­å–ã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆã‚¹ã‚­ãƒ£ãƒ³å“è³ªãŒä½ã„å¯èƒ½æ€§ï¼‰"
            else:
                reason = f"æœ¬æ–‡ãŒã»ã¼ç©ºã§ã™ï¼ˆ{text_len}æ–‡å­—ï¼‰"
        elif file_size > 30000 and text_len < 100:
            # 30KBè¶…ã®ãƒ•ã‚¡ã‚¤ãƒ«ãªã®ã«100æ–‡å­—æœªæº€ â†’ ç”»åƒPDFç­‰ã®å¯èƒ½æ€§ãŒé«˜ã„
            needs_rev = True
            reason = f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º({file_size // 1024}KB)ã«å¯¾ã—ã¦æœ¬æ–‡ãŒçŸ­ã™ãã¾ã™ï¼ˆ{text_len}æ–‡å­—ãƒ»ç”»åƒPDFç­‰ã®å¯èƒ½æ€§ï¼‰"

        summary = make_summary(main or text, int(cfg.get("summary_chars", 900)))
        payload = f"ã‚¿ã‚¤ãƒˆãƒ«(æ¨å®š): {title}\næ—¥ä»˜(æ¨å®š): {date_guess}\nç™ºå‡ºè€…(æ¨å®š): {issuer_guess}\n\n# æœ¬æ–‡\n{main.strip()}"
        if attach.strip(): payload += f"\n\n# æ·»ä»˜è³‡æ–™\n{attach.strip()}"

        log_lines.append(f"[{method}] {rel}")
        if reason:
            log_lines.append(f"  â†’ {reason}")

        records.append(Record(
            relpath=rel, ext=ext,
            size=file_size,
            mtime=os.path.getmtime(get_safe_path(path)),
            sha1=sha1, method=method, pages=pages,
            text_chars=len(text), needs_review=needs_rev, reason=reason,
            title_guess=title, date_guess=date_guess, issuer_guess=issuer_guess,
            summary=summary, tags_facility=fac, tags_work=work, tag_evidence=ev,
            out_txt="", full_text_for_bind=payload,
        ))

    write_excel_index(outdir, records)
    write_md_indices(outdir, records)
    write_binded_texts(outdir, records, limit_bytes)
    write_html_report(outdir, records)

    # ã‚µãƒãƒªãƒ¼ã‚’é›†è¨ˆã—ã¦ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    needs_rev_count = len([r for r in records if r.needs_review])
    review_breakdown: Dict[str, int] = {}
    for r in records:
        if r.needs_review:
            # ç†ç”±ã®å…ˆé ­éƒ¨åˆ†ï¼ˆ40æ–‡å­—ã¾ã§ï¼‰ã‚’ã‚­ãƒ¼ã«ã—ã¦é›†è¨ˆ
            key = r.reason[:40] if r.reason else r.method
            review_breakdown[key] = review_breakdown.get(key, 0) + 1

    log_lines += [
        "",
        "--- ã‚µãƒãƒªãƒ¼ ---",
        f"ç·å‡¦ç†æ•°: {len(records)} ä»¶ï¼ˆã†ã¡ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨: {skipped_cache} ä»¶ï¼‰",
        f"æ­£å¸¸æŠ½å‡º: {len(records) - needs_rev_count} ä»¶",
        f"è¦ç¢ºèª: {needs_rev_count} ä»¶",
    ]
    for k, v in sorted(review_breakdown.items(), key=lambda x: -x[1]):
        log_lines.append(f"  ãƒ»{k}: {v} ä»¶")
    if skipped_dup:
        log_lines.append(f"é‡è¤‡ã‚¹ã‚­ãƒƒãƒ—: {skipped_dup} ä»¶")

    with open(os.path.join(outdir, "00_å‡¦ç†ãƒ­ã‚°.txt"), "w", encoding="utf-8") as f:
        f.write("\n".join(log_lines))

    # ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’æ›´æ–°ï¼ˆæ¬¡å›ã®å·®åˆ†å‡¦ç†ã®ãŸã‚ã«å…¨ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ä¿å­˜ï¼‰
    manifest_new: Dict[str, dict] = {}
    for r in records:
        if r.sha1:
            manifest_new[r.sha1] = asdict(r)
    try:
        with open(manifest_path, "w", encoding="utf-8") as f:
            json.dump(manifest_new, f, ensure_ascii=False, separators=(",", ":"))
    except Exception:
        pass  # ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆä¿å­˜å¤±æ•—ã¯è‡´å‘½çš„ã§ã¯ãªã„

    breakdown_str = "ã€€".join(f"{k}: {v}ä»¶" for k, v in sorted(review_breakdown.items(), key=lambda x: -x[1]))
    return len(records), needs_rev_count, breakdown_str
